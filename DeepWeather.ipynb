{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wCRN7SHoM2-4","trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.io import read_image\n","import torchvision.transforms as T\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from sklearn.metrics import r2_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","!pip install jupyterplot\n","from jupyterplot import ProgressPlot\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkNdKJBLBcYn","trusted":true},"outputs":[],"source":["!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1mrIIEKob3yN6i52PaHy2RxJqzfHQfqaF' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1mrIIEKob3yN6i52PaHy2RxJqzfHQfqaF\" -O DeepWeatherDataset.zip && rm -rf /tmp/cookies.txt\n","!unzip DeepWeatherDataset.zip\n","!rm -rf __MACOSX"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:09:31.226983Z","iopub.status.busy":"2021-12-11T21:09:31.226697Z","iopub.status.idle":"2021-12-11T21:09:34.186636Z","shell.execute_reply":"2021-12-11T21:09:34.185585Z","shell.execute_reply.started":"2021-12-11T21:09:31.226948Z"},"id":"aYfUjvKVLMHc","trusted":true},"outputs":[],"source":["!mv DeepWeatherDataset/images ./\n","!mv DeepWeatherDataset/forecast.csv ./\n","!mv DeepWeatherDataset/observed.csv ./\n","!rm -rf DeepWeatherDataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:10:21.669203Z","iopub.status.busy":"2021-12-11T21:10:21.668890Z","iopub.status.idle":"2021-12-11T21:10:21.681997Z","shell.execute_reply":"2021-12-11T21:10:21.681241Z","shell.execute_reply.started":"2021-12-11T21:10:21.669158Z"},"id":"aa9ssRQXOF9F","trusted":true},"outputs":[],"source":["class DeepWeatherDataset(Dataset):\n","    def __init__(self, forecasts_file = 'forecast.csv', labels_file = 'observed.csv', img_dir = 'images'):\n","        self.forecasts = pd.read_csv(forecasts_file)\n","        self.labels = pd.read_csv(labels_file)\n","        self.img_dir = img_dir\n","        \n","        self.forecasts_means = self.forecasts.iloc[:, 3:].mean(axis = 0).values\n","        self.forecasts_std = self.forecasts.iloc[:, 3:].std(axis = 0).values\n","        self.labels_means = self.labels.iloc[:, 3:].mean(axis = 0).values\n","        self.labels_std = self.labels.iloc[:, 3:].std(axis = 0).values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        forecast = self.forecasts.iloc[idx, 3:]\n","        label = self.labels.iloc[idx, 3:]\n","        \n","        forecast = torch.tensor(forecast.values)\n","        label = torch.tensor(label.values)\n","\n","        truecolor_img_path = os.path.join(self.img_dir, str(idx) + '_truecolor.jpg')\n","        evi_img_path = os.path.join(self.img_dir, str(idx) + '_evi.jpg')\n","        ndmi_img_path = os.path.join(self.img_dir, str(idx) + '_ndmi.jpg')\n","\n","        truecolor_image = read_image(truecolor_img_path)\n","        evi_image = read_image(evi_img_path)\n","        ndmi_image = read_image(ndmi_img_path)\n","\n","        image = torch.zeros(9, truecolor_image.shape[1], truecolor_image.shape[2])\n","        image[:3, :, :] = truecolor_image\n","        image[3:6, :, :] = evi_image\n","        image[6:9, :, :] = ndmi_image\n","\n","        image /= 255.0\n","        \n","        forecast = (forecast - self.forecasts_means) / self.forecasts_std\n","        label = (label - self.labels_means) / self.labels_std\n","        \n","\n","        return [image, forecast], label"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:10:22.449623Z","iopub.status.busy":"2021-12-11T21:10:22.449068Z","iopub.status.idle":"2021-12-11T21:10:22.496552Z","shell.execute_reply":"2021-12-11T21:10:22.495812Z","shell.execute_reply.started":"2021-12-11T21:10:22.449578Z"},"id":"ujeYNSStERGn","trusted":true},"outputs":[],"source":["dataset = DeepWeatherDataset()\n","\n","train_len = int(len(dataset) * 0.8)\n","val_len = len(dataset) - train_len\n","\n","trainset, valset = torch.utils.data.random_split(dataset, [train_len, val_len])"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T00:03:40.391408Z","iopub.status.busy":"2021-12-12T00:03:40.390672Z","iopub.status.idle":"2021-12-12T00:03:40.740627Z","shell.execute_reply":"2021-12-12T00:03:40.737438Z","shell.execute_reply.started":"2021-12-12T00:03:40.391370Z"},"id":"JnZwz9bLHcHA","outputId":"c8f79255-4209-4216-c1b4-3ac1383550cb","trusted":true},"outputs":[],"source":["(image, forecast), label = dataset[np.random.randint(low = 0, high = len(dataset))]\n","\n","forecast = (forecast * dataset.forecasts_std) + dataset.forecasts_means\n","label = (label * dataset.labels_std) + dataset.labels_means\n","\n","print(f\"Forecast:\\n    Average Temp: {forecast[0]:.2f}K    Min Temp: {forecast[1]:.2f}K    Max Temp: {forecast[2]:.2f}K    Humidity: {forecast[4]:.2f}%    Clouds: {forecast[3]:.2f}%\")\n","print(f\"\\nLabel:\\n    Average Temp: {label[0]:.2f}K    Min Temp: {label[1]:.2f}K    Max Temp: {label[2]:.2f}K    Humidity: {label[3]:.2f}%\\n\")\n","\n","f = plt.figure(figsize = (10, 10))\n","plt.subplot(1, 3, 1)\n","plt.imshow(image[:3].permute(1, 2, 0) * 3)\n","plt.title('True Color')\n","plt.axis('off')\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(image[3:6].permute(1, 2, 0))\n","plt.title('EVI')\n","plt.axis('off')\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(image[6:9].permute(1, 2, 0))\n","plt.title('NDMI')\n","plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:10:26.971066Z","iopub.status.busy":"2021-12-11T21:10:26.970091Z","iopub.status.idle":"2021-12-11T21:10:26.984961Z","shell.execute_reply":"2021-12-11T21:10:26.984072Z","shell.execute_reply.started":"2021-12-11T21:10:26.971013Z"},"id":"byxTeA5rUiuG","trusted":true},"outputs":[],"source":["class DeepWeather(nn.Module):\n","    def __init__(self):\n","        super(DeepWeather, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels = 9, out_channels = 32, kernel_size = (3, 3), stride = 2)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.dropout = nn.Dropout(p = 0.3)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3, 3), stride = 2)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3, 3), stride = 2)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.fc1 = nn.Linear(6277, 1024)\n","        self.fc2 = nn.Linear(1024, 128)\n","        self.fc3 = nn.Linear(128, 4)\n","\n","    def forward(self, inputs):\n","        x1, x2 = inputs[0], inputs[1]\n","\n","        x1 = self.bn1(self.dropout(self.pool(F.leaky_relu(self.conv1(x1)))))\n","        x1 = self.bn2(self.dropout(self.pool(F.leaky_relu(self.conv2(x1)))))\n","        x1 = self.bn3(self.dropout(self.pool(F.leaky_relu(self.conv3(x1)))))\n","        x1 = torch.flatten(x1, start_dim = 1)\n","\n","        x = torch.cat((x1, x2), dim = 1)\n","        x = F.leaky_relu(self.fc1(x))\n","        x = F.leaky_relu(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:10:28.390345Z","iopub.status.busy":"2021-12-11T21:10:28.389014Z","iopub.status.idle":"2021-12-11T21:10:28.405412Z","shell.execute_reply":"2021-12-11T21:10:28.404512Z","shell.execute_reply.started":"2021-12-11T21:10:28.390295Z"},"id":"pXkUaJmmefOg","trusted":true},"outputs":[],"source":["def train(model, trainloader, valloader, criterion, optimizer, epochs, first_time = True, num_saved_epochs = 0):\n","    if not first_time:\n","        model = model.load_state_dict(torch.load(f'weights/epoch_{num_saved_epochs}'))\n","    \n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    model.to(device)\n","    \n","    pp = ProgressPlot(line_names = [\"Training Loss\"],\n","                      x_iterator=False,\n","                      x_label=\"Epochs\")\n","    \n","    running_loss = 0\n","    running_valloss = 0\n","    curr_iter = 0\n","    train_losses = []\n","    val_losses = []\n","    for epoch in range(epochs):\n","        with torch.no_grad():\n","            for i, data in enumerate(valloader):\n","                inputs, labels = data[0], data[1]\n","\n","                inputs[0] = inputs[0].float().to(device)\n","                inputs[1] = inputs[1].float().to(device)\n","                labels = labels.float().to(device)\n","\n","                outputs = model(inputs)\n","\n","                valloss = criterion(outputs, labels)\n","                running_valloss += valloss.item()\n","\n","            avg_valloss = running_valloss / (len(valloader) * (epoch + 1))\n","        \n","        progress_bar = tqdm(enumerate(trainloader), total = len(trainloader))\n","        for i, data in progress_bar:\n","            inputs, labels = data[0], data[1]\n","\n","            inputs[0] = inputs[0].float().to(device)\n","            inputs[1] = inputs[1].float().to(device)\n","            labels = labels.float().to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            curr_iter += 1\n","            \n","            progress_bar.set_description(\n","                f\"[{num_saved_epochs + epoch + 1}/{num_saved_epochs + epochs}][{i + 1}/{len(trainloader)}]\"\n","                f\"    Training Loss = {(running_loss / curr_iter):.4f}\"\n","                f\"    Validation Loss = {avg_valloss:.4f}\"\n","            )\n","            \n","            pp.update(curr_iter / len(trainloader), loss.item())\n","            \n","        train_losses.append((running_loss / curr_iter))\n","        val_losses.append(avg_valloss)\n","        \n","        torch.save(model.state_dict(), f'weights/epoch_{epoch + 1}')\n","\n","    return train_losses, val_losses"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:11:50.797058Z","iopub.status.busy":"2021-12-11T21:11:50.796756Z","iopub.status.idle":"2021-12-11T21:11:50.865574Z","shell.execute_reply":"2021-12-11T21:11:50.864806Z","shell.execute_reply.started":"2021-12-11T21:11:50.797026Z"},"id":"AKV2X85RFp7S","trusted":true},"outputs":[],"source":["#Uncomment the lines below if you want to train/load a pretrained model\n","#num_saved_epochs = 50\n","#model = model.load_state_dict(torch.load(f'weights/epoch_{num_saved_epochs}'))\n","\n","#Comment the (ONE) line below if you want to train/load a pretrained model\n","!mkdir weights\n","model = DeepWeather()\n","\n","trainloader = DataLoader(trainset, batch_size = 2, shuffle = True)\n","valloader = DataLoader(valset, batch_size = 2, shuffle = True)\n","\n","criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:11:56.070555Z","iopub.status.busy":"2021-12-11T21:11:56.069987Z","iopub.status.idle":"2021-12-11T21:58:07.613702Z","shell.execute_reply":"2021-12-11T21:58:07.612981Z","shell.execute_reply.started":"2021-12-11T21:11:56.070515Z"},"id":"RwAo5dpaH9lH","outputId":"046fb4bb-e399-46ee-d141-df943fcd47ff","trusted":true},"outputs":[],"source":["train_losses, val_losses = train(model, trainloader, valloader, criterion, optimizer, epochs = 50, first_time = True, num_saved_epochs = 0)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T22:00:59.350075Z","iopub.status.busy":"2021-12-11T22:00:59.349779Z","iopub.status.idle":"2021-12-11T22:00:59.545624Z","shell.execute_reply":"2021-12-11T22:00:59.544952Z","shell.execute_reply.started":"2021-12-11T22:00:59.350041Z"},"trusted":true},"outputs":[],"source":["epochs = [epoch for epoch in range(50)]\n","plt.plot(epochs, train_losses, label = 'Training Loss')\n","plt.plot(epochs, val_losses, label = 'Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T22:10:20.948734Z","iopub.status.busy":"2021-12-11T22:10:20.948080Z","iopub.status.idle":"2021-12-11T22:10:20.954384Z","shell.execute_reply":"2021-12-11T22:10:20.953403Z","shell.execute_reply.started":"2021-12-11T22:10:20.948700Z"},"trusted":true},"outputs":[],"source":["def predict(model, dataset, inputs):\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    \n","    model = model.to(device)\n","    inputs[0] = inputs[0].float().to(device)\n","    inputs[1] = inputs[1].float().to(device)\n","    \n","    outputs = model(inputs)\n","    outputs = (outputs.cpu().detach().numpy() * dataset.labels_std) + dataset.labels_means\n","    \n","    return outputs"]},{"cell_type":"code","execution_count":143,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T00:04:30.252221Z","iopub.status.busy":"2021-12-12T00:04:30.251516Z","iopub.status.idle":"2021-12-12T00:04:30.289045Z","shell.execute_reply":"2021-12-12T00:04:30.288358Z","shell.execute_reply.started":"2021-12-12T00:04:30.252182Z"},"trusted":true},"outputs":[],"source":["data = valset[np.random.randint(low = 0, high = len(valset))]\n","\n","inputs = data[0]\n","inputs[0] = inputs[0].unsqueeze(0)\n","inputs[1] = inputs[1].unsqueeze(0)\n","\n","label = (data[1] * dataset.labels_std) + dataset.labels_means\n","forecast = (inputs[1] * dataset.forecasts_std) + dataset.forecasts_means\n","\n","prediction = predict(model, dataset, inputs)\n","\n","forecast = forecast.squeeze()\n","prediction = prediction.squeeze()\n","\n","print(f\"Forecast:\\n    Average Temp: {forecast[0]:.2f}K    Min Temp: {forecast[1]:.2f}K    Max Temp: {forecast[2]:.2f}K    Humidity: {forecast[4]:.2f}%    Clouds: {forecast[3]:.2f}%\")\n","print(f\"\\nLabel:\\n    Average Temp: {label[0]:.2f}K    Min Temp: {label[1]:.2f}K    Max Temp: {label[2]:.2f}K    Humidity: {label[3]:.2f}%\")\n","print(f\"\\nPrediction:\\n    Average Temp: {prediction[0]:.2f}K    Min Temp: {prediction[1]:.2f}K    Max Temp: {prediction[2]:.2f}K    Humidity: {prediction[3]:.2f}%\")"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T23:35:22.171676Z","iopub.status.busy":"2021-12-11T23:35:22.171409Z","iopub.status.idle":"2021-12-11T23:37:11.661566Z","shell.execute_reply":"2021-12-11T23:37:11.659906Z","shell.execute_reply.started":"2021-12-11T23:35:22.171646Z"},"trusted":true},"outputs":[],"source":["trainloader = DataLoader(trainset, batch_size = 128, shuffle = False)\n","train_r2 = 0\n","train_avg_temp_r2 = 0\n","train_min_temp_r2 = 0\n","train_max_temp_r2 = 0\n","train_humidity_r2 = 0\n","for i, data in enumerate(trainloader):\n","    inputs = data[0]\n","    labels = data[1]\n","    labels = (labels * dataset.labels_std) + dataset.labels_means\n","    \n","    outputs = predict(model, dataset, inputs)\n","    \n","    train_r2 += r2_score(labels, outputs)\n","    train_avg_temp_r2 += r2_score(labels[:, 0], outputs[:, 0])\n","    train_min_temp_r2 += r2_score(labels[:, 1], outputs[:, 1])\n","    train_max_temp_r2 += r2_score(labels[:, 2], outputs[:, 2])\n","    train_humidity_r2 += r2_score(labels[:, 3], outputs[:, 3])\n","    \n","train_r2 /= len(trainloader)\n","train_avg_temp_r2 /= len(trainloader)\n","train_min_temp_r2 /= len(trainloader)\n","train_max_temp_r2 /= len(trainloader)\n","train_humidity_r2 /= len(trainloader)\n","\n","print(\"Training Data R2 Scores:\")\n","print(f\"    Avg Temp: {train_avg_temp_r2:.3f}\")\n","print(f\"    Min Temp: {train_min_temp_r2:.3f}\")\n","print(f\"    Max Temp: {train_max_temp_r2:.3f}\")\n","print(f\"    Humidity: {train_humidity_r2:.3f}\")\n","print(f\"    Total: {train_r2:.3f}\")\n","    \n","    \n","    \n","    \n","valloader = DataLoader(valset, batch_size = 128, shuffle = False)\n","val_r2 = 0\n","val_avg_temp_r2 = 0\n","val_min_temp_r2 = 0\n","val_max_temp_r2 = 0\n","val_humidity_r2 = 0\n","for i, data in enumerate(valloader):\n","    inputs = data[0]\n","    labels = data[1]\n","    labels = (labels * dataset.labels_std) + dataset.labels_means\n","    \n","    outputs = predict(model, dataset, inputs)\n","    \n","    val_r2 += r2_score(labels, outputs)\n","    val_avg_temp_r2 += r2_score(labels[:, 0], outputs[:, 0])\n","    val_min_temp_r2 += r2_score(labels[:, 1], outputs[:, 1])\n","    val_max_temp_r2 += r2_score(labels[:, 2], outputs[:, 2])\n","    val_humidity_r2 += r2_score(labels[:, 3], outputs[:, 3])\n","    \n","val_r2 /= len(valloader)\n","val_avg_temp_r2 /= len(valloader)\n","val_min_temp_r2 /= len(valloader)\n","val_max_temp_r2 /= len(valloader)\n","val_humidity_r2 /= len(valloader)\n","\n","print(\"\\nValidation Data R2 Scores:\")\n","print(f\"    Avg Temp: {val_avg_temp_r2:.3f}\")\n","print(f\"    Min Temp: {val_min_temp_r2:.3f}\")\n","print(f\"    Max Temp: {val_max_temp_r2:.3f}\")\n","print(f\"    Humidity: {val_humidity_r2:.3f}\")\n","print(f\"    Total: {val_r2:.3f}\")\n","\n","\n","\n","\n","dataloader = DataLoader(dataset, batch_size = 128)\n","forecast_r2 = 0\n","forecast_avg_temp_r2 = 0\n","forecast_min_temp_r2 = 0\n","forecast_max_temp_r2 = 0\n","forecast_humidity_r2 = 0\n","for i, data in enumerate(dataloader):\n","    inputs = data[0]\n","    labels = data[1]\n","    forecasts = inputs[1]\n","    forecasts = forecasts[:, np.r_[:3, 4]]\n","    \n","    forecast_avg_temp_r2 += r2_score(labels[:, 0], forecasts[:, 0])\n","    forecast_min_temp_r2 += r2_score(labels[:, 1], forecasts[:, 1])\n","    forecast_max_temp_r2 += r2_score(labels[:, 2], forecasts[:, 2])\n","    forecast_humidity_r2 += r2_score(labels[:, 3], forecasts[:, 3])\n","    forecast_r2 += r2_score(forecasts, labels)\n","    \n","forecast_r2 /= len(dataloader)\n","forecast_avg_temp_r2 /= len(dataloader)\n","forecast_min_temp_r2 /= len(dataloader)\n","forecast_max_temp_r2 /= len(dataloader)\n","forecast_humidity_r2 /= len(dataloader)\n","\n","print(\"\\nForecast Data R2 Scores:\")\n","print(f\"    Avg Temp: {forecast_avg_temp_r2:.3f}\")\n","print(f\"    Min Temp: {forecast_min_temp_r2:.3f}\")\n","print(f\"    Max Temp: {forecast_max_temp_r2:.3f}\")\n","print(f\"    Humidity: {forecast_humidity_r2:.3f}\")\n","print(f\"    Total: {forecast_r2:.3f}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
